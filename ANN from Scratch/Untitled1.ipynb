{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and functions to load the data\n",
    "from digits import get_mnist\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import ast\n",
    "import sys\n",
    "import numpy.testing as npt\n",
    "import pytest\n",
    "import random\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trX.shape:  (784, 60000)\n",
      "trY.shape:  (1, 60000)\n",
      "tsX.shape:  (784, 10000)\n",
      "tsY.shape:  (1, 10000)\n",
      "Train max: value = 1.0, Train min: value = -1.0\n",
      "Test max: value = 1.0, Test min: value = -1.0\n",
      "Unique labels in train:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Unique labels in test:  [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "Displaying a few samples\n",
      "labels\n",
      "[[5 0 4 1 9 2 1 3 1 4]\n",
      " [3 5 3 6 1 7 2 8 6 9]\n",
      " [4 0 9 1 1 2 4 3 2 7]\n",
      " [3 8 6 9 0 5 6 0 7 6]\n",
      " [1 8 7 9 3 9 8 5 9 3]\n",
      " [7 2 1 0 4 1 4 9 5 9]\n",
      " [0 6 9 0 1 5 9 7 3 4]\n",
      " [9 6 6 5 4 0 7 4 0 1]\n",
      " [3 1 3 4 7 2 7 1 2 1]\n",
      " [1 7 4 2 3 5 1 2 4 4]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "trX, trY, tsX, tsY = get_mnist()\n",
    "# We need to reshape the data everytime to match the format (d,m), where d is dimensions (784) and m is number of samples\n",
    "trX = trX.reshape(-1, 28*28).T\n",
    "trY = trY.reshape(1, -1)\n",
    "tsX = tsX.reshape(-1, 28*28).T\n",
    "tsY = tsY.reshape(1, -1)\n",
    "    \n",
    "# Lets examine the data and see if it is normalized\n",
    "print('trX.shape: ', trX.shape)\n",
    "print('trY.shape: ', trY.shape)\n",
    "print('tsX.shape: ', tsX.shape)\n",
    "print('tsY.shape: ', tsY.shape)\n",
    "print('Train max: value = {}, Train min: value = {}'.format(np.max(trX), np.min(trX)))\n",
    "print('Test max: value = {}, Test min: value = {}'.format(np.max(tsX), np.min(tsX)))\n",
    "print('Unique labels in train: ', np.unique(trY))\n",
    "print('Unique labels in test: ', np.unique(tsY))\n",
    "\n",
    "# Let's visualize a few samples and their labels from the train and test datasets.\n",
    "print('\\nDisplaying a few samples')\n",
    "visx = np.concatenate((trX[:,:50],tsX[:,:50]), axis=1).reshape(28,28,10,10).transpose(2,0,3,1).reshape(28*10,-1)\n",
    "visy = np.concatenate((trY[:,:50],tsY[:,:50]), axis=1).reshape(10,-1)\n",
    "    \n",
    "print('labels')\n",
    "print(visy)\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.axis('off')\n",
    "plt.imshow(visx, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    '''\n",
    "    Computes relu activation of input Z\n",
    "    \n",
    "    Inputs: \n",
    "        Z: numpy.ndarray (n, m) which represent 'm' samples each of 'n' dimension\n",
    "        \n",
    "    Outputs: \n",
    "        A: where A = ReLU(Z) is a numpy.ndarray (n, m) representing 'm' samples each of 'n' dimension\n",
    "        cache: a dictionary with {\"Z\", Z}\n",
    "        \n",
    "    '''\n",
    "    cache = {}\n",
    "    # your code here\n",
    "    if type(Z) is list: \n",
    "        Z = np.asarray(Z)\n",
    "        \n",
    "    A = np.maximum(np.zeros((Z.shape)), Z)\n",
    "    cache[\"Z\"] = Z    \n",
    "\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_der(dA, cache):\n",
    "    '''\n",
    "    Computes derivative of relu activation\n",
    "    \n",
    "    Inputs: \n",
    "        dA: derivative from the subsequent layer of dimension (n, m). \n",
    "            dA is multiplied elementwise with the gradient of ReLU\n",
    "        cache: dictionary with {\"Z\", Z}, where Z was the input \n",
    "            to the activation layer during forward propagation\n",
    "        \n",
    "    Outputs: \n",
    "        dZ: the derivative of dimension (n,m). It is the elementwise \n",
    "            product of the derivative of ReLU and dA\n",
    "        \n",
    "    '''\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    Z = cache[\"Z\"]\n",
    "    # your code here\n",
    "    dRelu = np.where(Z <= 0, 0, 1) \n",
    "    dZ = np.multiply(dZ, dRelu)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(Z):\n",
    "    '''\n",
    "    Computes linear activation of Z\n",
    "    This function is implemented for completeness\n",
    "        \n",
    "    Inputs: \n",
    "        Z: numpy.ndarray (n, m) which represent 'm' samples each of 'n' dimension\n",
    "        \n",
    "    Outputs: \n",
    "        A: where A = Linear(Z) is a numpy.ndarray (n, m) representing 'm' samples each of 'n' dimension\n",
    "        cache: a dictionary with {\"Z\", Z}   \n",
    "    '''\n",
    "    A = Z\n",
    "    cache = {}\n",
    "    cache[\"Z\"] = Z\n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def linear_der(dA, cache):\n",
    "    '''\n",
    "    Computes derivative of linear activation\n",
    "    This function is implemented for completeness\n",
    "    \n",
    "    Inputs: \n",
    "        dA: derivative from the subsequent layer of dimension (n, m). \n",
    "            dA is multiplied elementwise with the gradient of Linear(.)\n",
    "        cache: dictionary with {\"Z\", Z}, where Z was the input \n",
    "            to the activation layer during forward propagation\n",
    "        \n",
    "    Outputs: \n",
    "        dZ: the derivative of dimension (n,m). It is the elementwise \n",
    "            product of the derivative of Linear(.) and dA\n",
    "    '''      \n",
    "    dZ = np.array(dA, copy=True)\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cross_entropy_loss(Z, Y=np.array([])):\n",
    "    '''\n",
    "    Computes the softmax activation of the inputs Z\n",
    "    Estimates the cross entropy loss\n",
    "\n",
    "    Inputs: \n",
    "        Z: numpy.ndarray (n, m)\n",
    "        Y: numpy.ndarray (1, m) of labels\n",
    "            when y=[] loss is set to []\n",
    "    \n",
    "    Outputs:\n",
    "        A: numpy.ndarray (n, m) of softmax activations\n",
    "        cache: a dictionary to store the activations which will be used later to estimate derivatives\n",
    "        loss: cost of prediction\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    A = np.exp(Z)/ np.sum(np.exp(Z), axis=0, keepdims = True)\n",
    "    if Y.size == 0:\n",
    "        loss = 0.0\n",
    "    else: \n",
    "        Y_oneHot = np.zeros((A.shape))\n",
    "        Y_oneHot[Y.astype(int), np.arange(Y.shape[1])] = 1\n",
    "        loss = -np.mean(np.sum(Y_oneHot * np.log(A), axis=0, keepdims=True))\n",
    "        \n",
    "        \n",
    "    cache = {}\n",
    "    cache[\"A\"] = A\n",
    "    return A, cache, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cross_entropy_loss_der(Y, cache):\n",
    "    '''\n",
    "    Computes the derivative of the softmax activation and cross entropy loss\n",
    "\n",
    "    Inputs: \n",
    "        Y: numpy.ndarray (1, m) of labels\n",
    "        cache: a dictionary with cached activations A of size (n,m)\n",
    "\n",
    "    Outputs:\n",
    "        dZ: derivative dL/dZ - a numpy.ndarray of dimensions (n, m) \n",
    "    '''\n",
    "    A = cache[\"A\"]\n",
    "    # your code here\n",
    "    Y_oneHot = np.zeros((A.shape))\n",
    "    Y_oneHot[Y.astype(int), np.arange(Y.shape[1])] = 1\n",
    "\n",
    "    dZ = (A - Y_oneHot)/Y.shape[1]\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(A, drop_prob, mode='train'):\n",
    "        '''\n",
    "        Using the 'inverted dropout' technique to implement dropout regularization.\n",
    "        Inputs:\n",
    "            A: Activation input before dropout is applied - shape is (n,m)\n",
    "            drop_prob: dropout parameter. If drop_prob = 0.3, we drop 30% of the neuron activations\n",
    "            mode: Dropout acts differently in training and testing mode. Hence, mode is a parameter which\n",
    "                takes in only 2 values, 'train' or 'test'\n",
    "\n",
    "        Outputs:\n",
    "            A: Output of shape (n,m), with some values masked out and other values scaled to account for missing values\n",
    "            cache: a tuple which stores the drop_prob, mode and mask for use in backward pass.\n",
    "        '''\n",
    "        # When there is no dropout return the same activation\n",
    "        mask = None\n",
    "        if drop_prob == 0:\n",
    "            cache = (drop_prob, mode, mask)\n",
    "            return A, cache\n",
    "        \n",
    "        # The prob_keep is the percentage of activations remaining after dropout\n",
    "        # if drop_out = 0.3, then prob_keep = 0.7, i.e., 70% of the activations are retained\n",
    "        prob_keep = 1-drop_prob\n",
    "        \n",
    "        # Note: instead of a binary mask implement a scaled mask, where mask is scaled by dividing it \n",
    "        # by the prob_keep for example, if we have input activations of size (3,4), then the mask is \n",
    "        # mask = (np.random.rand(3,4)<prob_keep)/prob_keep\n",
    "        # We perform the scaling by prob_keep here so we don't have to do it specifically during backpropagation \n",
    "        # We then update A by multiplying it element wise with the mask\n",
    "        \n",
    "        if mode == 'train':\n",
    "            # your code here\n",
    "            mask = (np.random.rand(A.shape[0],A.shape[1]) < prob_keep)/prob_keep\n",
    "            A = A *  mask\n",
    "            \n",
    "        elif mode != 'test':\n",
    "            raise ValueError(\"Mode value not set correctly, set it to 'train' or 'test'\")\n",
    "        cache = (drop_prob, mode, mask)\n",
    "        return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_der(dA_in, cache):\n",
    "        '''\n",
    "        Backward pass for the inverted dropout.\n",
    "        Inputs: \n",
    "            dA_in: derivative from the upper layers of dimension (n,m).\n",
    "            cache: tuple containing (drop_out, mode, mask), where drop_out is the probability of drop_out, \n",
    "                if drop_out=0, then the layer does not have any dropout,\n",
    "                mode is either 'train' or 'test' and \n",
    "                mask is a matirx of size (n,m) where 0's indicate masked values\n",
    "        Outputs:\n",
    "            dA_out = derivative of the dropout layer of dimension (n,m)\n",
    "        '''\n",
    "        \n",
    "        dA_out = None\n",
    "        drop_out, mode, mask = cache\n",
    "        # If there is no dropout return the same derivative from the previous layer\n",
    "        if not drop_out:\n",
    "            return dA_in\n",
    "        \n",
    "        # if mode is 'train' dA_out is dA_in multiplied element wise by mask\n",
    "        # if mode is 'test' dA_out is same as dA_in\n",
    "        # your code here\n",
    "        if mode == 'train':\n",
    "            dA_out = dA_in * mask\n",
    "        else:\n",
    "            dA_out = dA_in\n",
    "            \n",
    "        return dA_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm(A, beta, gamma):\n",
    "    '''\n",
    "    Batchnorm normalizes the input A to mean beta and standard deviation gamma\n",
    "    \n",
    "    Inputs: \n",
    "        A: Activation input after activation - shape is (n,m), m samples where each sample x is (n,1)\n",
    "        beta: mean vector which will be the center of the data after batchnorm - shape is (n,1)\n",
    "        gamma: standard deviation vector which will be scale of the data after batchnorm - shape (n,1)\n",
    "        \n",
    "    Outputs: \n",
    "        Anorm: Normalized version of input A - shape (n,m)\n",
    "        cache: Dictionary of the elements that are necessary for backpropagation\n",
    "    '''\n",
    "    \n",
    "    # When there is no batch norm for a layer, the beta and gamma will be empty arrays\n",
    "    if beta.size == 0 or gamma.size == 0:\n",
    "        cache = {}\n",
    "        return A, cache\n",
    "    # epsilon value used for scaling during normalization to avoid divide by zero. \n",
    "    # don't change this value - the test case will fail if you change this value\n",
    "    epsilon = 1e-5\n",
    "    # your code here\n",
    "    '''\n",
    "    # Calculating mean and variance\n",
    "    mu = np.sum(A, axis = 1, keepdims = True)/A.shape[1]\n",
    "    var = np.sum((A - mu)**2, axis = 1,keepdims = True)/A.shape[1]\n",
    "    \n",
    "    # Getting Normalized values of A (Zero mean and Unit variance)\n",
    "    Ahat = (A - mu)/ np.sqrt(var + epsilon)\n",
    "\n",
    "    # Transforming Normalized A (Ahat) to Anorm (with beta mean and gamma variance) \n",
    "    Anorm = (gamma * Ahat) + beta\n",
    "    '''\n",
    "    \n",
    "    n, m = A.shape\n",
    "    \n",
    "    #step1: calculatemean\n",
    "    mu = np.sum(A,axis=1, keepdims = True)/m\n",
    "    \n",
    "    #step2: subtract mean vector of every trainings example\n",
    "    Amu = A - mu\n",
    "\n",
    "    #step3: following the lower branch - calculation denominator\n",
    "    sq = Amu ** 2\n",
    "\n",
    "    #step4: calculate variance\n",
    "    var = np.sum(sq, axis=1, keepdims = True)/m         ##################### np.nansum\n",
    "\n",
    "    #step5: add epsilon for numerical stability, then sqrt\n",
    "    sqrtvar = np.sqrt(var + epsilon)\n",
    "\n",
    "    #step6: invert sqrtvar\n",
    "    ivar = 1./sqrtvar\n",
    "\n",
    "    #step7: execute normalization\n",
    "    Ahat = Amu * ivar\n",
    "\n",
    "    #step8: Nor the two transformation steps\n",
    "    gammaA = gamma * Ahat\n",
    "\n",
    "    #step9\n",
    "    Anorm = gammaA + beta\n",
    "\n",
    "    #store intermediate\n",
    "    cache = (Ahat,gamma,Amu,ivar,sqrtvar,var,epsilon)    \n",
    "    \n",
    "    return Anorm, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm_der(dA_in, cache):\n",
    "    '''\n",
    "    Derivative of the batchnorm\n",
    "    Inputs: \n",
    "        dA_in: derivative from the upper layers of dimension (n,m).\n",
    "        cache: Dictionary of the elements that are necessary for backpropagation\n",
    "    Outputs:\n",
    "        dA_out: derivative of the batchnorm layer of dimension (n,m)\n",
    "        dbeta: derivative of beta - shape (n,1)\n",
    "        dgamma: derivative of gamma - shape (n,1)\n",
    "    '''\n",
    "    # When the cache is empty, it indicates there was no batchnorm for the layer\n",
    "    if not cache:\n",
    "        dbeta = []\n",
    "        dgamma = []\n",
    "        return dA_in, dbeta, dgamma\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    #unfold the variables stored in cache\n",
    "    xhat,gamma,xmu,ivar,sqrtvar,var,eps = cache\n",
    "    \n",
    "    # get the dimensions of the input/output\n",
    "    n, m = dA_in.shape\n",
    "    \n",
    "    #step9\n",
    "    dbeta = np.sum(dA_in, axis=1, keepdims = True)\n",
    "    dgammax = dA_in\n",
    "    \n",
    "    #step8\n",
    "    dgamma = np.sum(dgammax * xhat, axis=1, keepdims = True)\n",
    "    dxhat  = dgammax * gamma\n",
    "    \n",
    "    #step7\n",
    "    divar = np.sum(dxhat*xmu, axis=1, keepdims = True)\n",
    "    dxmu1 = dxhat * ivar\n",
    "\n",
    "    #step6\n",
    "    dsqrtvar = -1. /(sqrtvar**2) * divar\n",
    "\n",
    "    #step5\n",
    "    dvar = 0.5 * 1. /np.sqrt(var+eps) * dsqrtvar\n",
    "\n",
    "    #step4\n",
    "    dsq = (np.ones((n,m)) * dvar)/m\n",
    "\n",
    "    #step3\n",
    "    dxmu2 = 2 * xmu * dsq\n",
    "\n",
    "    #step2\n",
    "    dx1 = (dxmu1 + dxmu2)\n",
    "    dmu = -1 * np.sum(dxmu1+dxmu2, axis=1, keepdims = True)\n",
    "\n",
    "    #step1\n",
    "    dx2 = (np.ones((n,m)) * dmu)/m\n",
    "\n",
    "    #step0\n",
    "    dA_out = dx1 + dx2\n",
    "    \n",
    "    \n",
    "    return dA_out, dbeta, dgamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(net_dims, act_list, drop_prob_list):\n",
    "    '''\n",
    "    Initializes the parameters W's and b's of a multi-layer neural network\n",
    "    Adds information about dropout and activations in each layer\n",
    "    \n",
    "    Inputs:\n",
    "        net_dims: List containing the dimensions of the network. The values of the array represent the number of nodes in \n",
    "        each layer. For Example, if a Neural network contains 784 nodes in the input layer, 800 in the first hidden layer, \n",
    "        500 in the secound hidden layer and 10 in the output layer, then net_dims = [784,800,500,10]. \n",
    "        act_list: list of strings indicating the activation for a layer\n",
    "        drop_prob_list: list of dropout probabilities for each layer \n",
    "    \n",
    "    Outputs:\n",
    "        parameters: dictionary of \n",
    "                    {\"numLayers\":..}\n",
    "                    activations, {\"act1\":\"..\", \"act2\":\"..\", ...}\n",
    "                    dropouts, {\"dropout1\": .. , \"dropout2\": .., ...}\n",
    "                    network parameters, {\"W1\":[..],\"b1\":[..],\"W2\":[..],\"b2\":[..],...}\n",
    "            The weights are initialized using Kaiming He et al. Initialization\n",
    "    '''\n",
    "    net_dims_len = len(net_dims)\n",
    "    parameters = {}\n",
    "    parameters['numLayers'] = net_dims_len - 1;\n",
    "    for l in range(net_dims_len-1):\n",
    "        parameters[\"act\"+str(l+1)] = act_list[l]\n",
    "        parameters[\"dropout\"+str(l+1)] = drop_prob_list[l]\n",
    "        # Note: Use He et al. Initialization to initialize W and set bias to 0's\n",
    "        # parameters[\"W\"+str(l+1)] = \n",
    "        # parameters[\"b\"+str(l+1)] =\n",
    "        # your code here\n",
    "        parameters[\"W\"+str(l+1)] = np.random.randn(net_dims[l+1],net_dims[l])*(2./np.sqrt(net_dims[l]))\n",
    "        parameters[\"b\"+str(l+1)] = np.zeros((net_dims[l+1],1))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_velocity(parameters, apply_momentum=True):\n",
    "    '''\n",
    "    The function will add Adam momentum parameters, Velocity and Gradient-Squares \n",
    "    to the parameters for each of the W's and b's \n",
    "    \n",
    "    Inputs: \n",
    "        parameters: dictionary containing, \n",
    "                    {\"numLayers\":..}\n",
    "                    activations, {\"act1\":\"..\", \"act2\":\"..\", ...}\n",
    "                    dropouts, {\"dropout1\": .. , \"dropout2\": .., ...}\n",
    "                    network parameters, {\"W1\":[..],\"b1\":[..],\"W2\":[..],\"b2\":[..],...}\n",
    "                    Note: It is just one dictionary (parameters) with all these key value pairs, not multiple dictionaries\n",
    "        apply_momentum: boolean on whether to apply momentum\n",
    "        \n",
    "    Outputs:\n",
    "        parameters: dictionary that has been updated to include velocity and Gradient-Squares. It now contains,\n",
    "                    {\"numLayers\":..}\n",
    "                    activations, {\"act1\":\"..\", \"act2\":\"..\", ...}\n",
    "                    dropouts, {\"dropout1\": .. , \"dropout2\": .., ...}\n",
    "                    {\"apply_momentum\":..}\n",
    "                    velocity parameters, {\"VdW1\":[..],\"Vdb1\":[..],\"VdW2\":[..],\"Vdb2\":[..],...}\n",
    "                    Gradient-Squares parameters, {\"GdW1\":[..],\"Gdb1\":[..],\"GdW2\":[..],\"Gdb2\":[..],...}\n",
    "                    Note: It is just one dictionary (parameters) with all these key value pairs, not multiple dictionaries\n",
    "    '''\n",
    "    \n",
    "    L = parameters['numLayers'] \n",
    "    parameters['apply_momentum'] = apply_momentum\n",
    "    \n",
    "    # Initialize Velocity and the Gradient-Squares to zeros the same size as the corresponding parameters W's abd b's\n",
    "    for l in range(L):\n",
    "        if apply_momentum:\n",
    "            # Hint: Velocity parameters are represented as VdW and Vdb\n",
    "            #      Gradient-Squares are represented as GdW and Gdb\n",
    "            # You can use np.zeros_like(.) to initilaize them 0's the same size as corresponding parameters W and b\n",
    "            # parameters[\"VdW\" + str(l+1)] = \n",
    "            # parameters[\"Vdb\" + str(l+1)] =\n",
    "            # parameters[\"GdW\" + str(l+1)] =\n",
    "            # parameters[\"Gdb\" + str(l+1)] =\n",
    "            # your code here\n",
    "            parameters[\"VdW\" + str(l+1)] = np.zeros_like(parameters[\"W\"+str(l+1)])\n",
    "            parameters[\"Vdb\" + str(l+1)] = np.zeros_like(parameters[\"b\"+str(l+1)])\n",
    "            parameters[\"GdW\" + str(l+1)] = np.zeros_like(parameters[\"W\"+str(l+1)])\n",
    "            parameters[\"Gdb\" + str(l+1)] = np.zeros_like(parameters[\"b\"+str(l+1)])    \n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bnorm_params(parameters, bnorm_list, apply_momentum):\n",
    "    '''\n",
    "    The function will add batchnorm parameters beta's and gamma's and their corresponding\n",
    "    Velocity and Gradient-Squares to the parameters dictionary\n",
    "    \n",
    "    Inputs: \n",
    "        parameters: dictionary that contains,\n",
    "                    {\"numLayers\":..}\n",
    "                    activations, {\"act1\":\"..\", \"act2\":\"..\", ...}\n",
    "                    dropouts, {\"dropout1\": .. , \"dropout2\": .., ...}\n",
    "                    {\"apply_momentum\":..}\n",
    "                    velocity parameters, {\"VdW1\":[..],\"Vdb1\":[..],\"VdW2\":[..],\"Vdb2\":[..],...}\n",
    "                    Gradient-Squares parameters, {\"GdW1\":[..],\"Gdb1\":[..],\"GdW2\":[..],\"Gdb2\":[..],...}\n",
    "                    Note: It is just one dictionary (parameters) with all these key value pairs, not multiple dictionaries\n",
    "        bnorm_list: binary list indicating if batchnorm should be implemented for a layer\n",
    "        apply_momentum: boolean on whether to apply momentum\n",
    "        \n",
    "    Outputs:\n",
    "        parameters: dictionary that has been updated to include batchnorm parameters, beta, gamma \n",
    "                    and their corresponding momentum parameters. It now contains,\n",
    "                    {\"numLayers\":..}\n",
    "                    activations, {\"act1\":\"..\", \"act2\":\"..\", ...}\n",
    "                    dropouts, {\"dropout1\": .. , \"dropout2\": .., ...}\n",
    "                    velocity parameters, {\"VdW1\":[..],\"Vdb1\":[..],\"VdW2\":[..],\"Vdb2\":[..],...}\n",
    "                    Gradient-Squares parameters, {\"GdW1\":[..],\"Gdb1\":[..],\"GdW2\":[..],\"Gdb2\":[..],...}\n",
    "                    {\"bnorm_list\":..}\n",
    "                    batchnorm parameters, {\"bnorm_beta1\":[..],\"bnorm_gamma1\":[..],\"bnorm_beta2\":[..],\"bnorm_gamma2\":[..],...}\n",
    "                    batchnorm velocity parameters, {\"Vbnorm_beta1\":[..],\"Vbnorm_gamma1\":[..],\"Vbnorm_beta2\":[..],\"Vbnorm_gamma2\":[..],...}\n",
    "                    batchnorm Gradient-Square parameters, {\"Gbnorm_beta1\":[..],\"Gbnorm_gamma1\":[..],\"Gbnorm_beta2\":[..],\"Gbnorm_gamma2\":[..],...}\n",
    "                    Note: It is just one dictionary (parameters) with all these key value pairs, not multiple dictionaries\n",
    "    '''\n",
    "    \n",
    "    L = parameters['numLayers']\n",
    "    parameters['bnorm_list'] = bnorm_list\n",
    "    \n",
    "    # Initialize batchnorm parameters for the hidden layers only. \n",
    "    # Each hidden layer will have a dictionary of parameters, beta and gamma based on the dimensions of the hidden layer. \n",
    "    for l in range(L):\n",
    "        if bnorm_list[l]:\n",
    "            n = parameters[\"W\" + str(l+1)].shape[0]\n",
    "            parameters['bnorm_beta'+str(l+1)] = np.random.randn(n,1)\n",
    "            parameters['bnorm_gamma'+str(l+1)] = np.random.randn(n,1)\n",
    "            if apply_momentum:\n",
    "                parameters['Vbnorm_beta'+str(l+1)] = np.zeros((n,1))\n",
    "                parameters['Gbnorm_beta'+str(l+1)] = np.zeros((n,1))\n",
    "                parameters['Vbnorm_gamma'+str(l+1)] = np.zeros((n,1))\n",
    "                parameters['Gbnorm_gamma'+str(l+1)] = np.zeros((n,1))\n",
    "        else:\n",
    "            parameters['bnorm_beta'+str(l+1)] = np.asarray([])\n",
    "            parameters['Vbnorm_beta'+str(l+1)] = np.asarray([])\n",
    "            parameters['Gbnorm_beta'+str(l+1)] = np.asarray([])\n",
    "            parameters['bnorm_gamma'+str(l+1)] = np.asarray([])\n",
    "            parameters['Vbnorm_gamma'+str(l+1)] = np.asarray([])\n",
    "            parameters['Gbnorm_gamma'+str(l+1)] = np.asarray([])\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A_prev, W, b):\n",
    "    '''\n",
    "    Input A_prev propagates through the layer \n",
    "    Z = WA + b is the output of this layer. \n",
    "\n",
    "    Inputs: \n",
    "        A_prev: numpy.ndarray (n,m) the input to the layer\n",
    "        W: numpy.ndarray (n_out, n) the weights of the layer\n",
    "        b: numpy.ndarray (n_out, 1) the bias of the layer\n",
    "\n",
    "    Outputs:\n",
    "        Z: where Z = W.A_prev + b, where Z is the numpy.ndarray (n_out, m) dimensions\n",
    "        cache: a dictionary containing the inputs A\n",
    "    '''\n",
    "    # your code here\n",
    "    Z = np.dot(W, A_prev) + b\n",
    "    #Z = np.where(np.isnan(W),0,W).dot(np.where(np.isnan(A_prev),0,A_prev))\n",
    "    # assert(Z.shape == (W.shape[0], A_prev.shape[1]))\n",
    "\n",
    "    cache = {}\n",
    "    cache[\"A\"] = A_prev\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_forward(A_prev, W, b, activation, drop_prob, bnorm_beta, bnorm_gamma, mode):\n",
    "    '''\n",
    "    Input A_prev propagates through the layer followed by activation, batchnorm and dropout\n",
    "\n",
    "    Inputs: \n",
    "        A_prev: numpy.ndarray (n,m) the input to the layer\n",
    "        W: numpy.ndarray (n_out, n) the weights of the layer\n",
    "        b: numpy.ndarray (n_out, 1) the bias of the layer\n",
    "        activation: is the string that specifies the activation function\n",
    "        drop_prob: dropout parameter. If drop_prob = 0.3, we drop 30% of the neuron activations\n",
    "        bnorm_beta: batchnorm beta \n",
    "        bnorm_gamma: batchnorm gamma\n",
    "        mode: 'train' or 'test' Dropout acts differently in training and testing mode. Hence, mode is a parameter which\n",
    "                takes in only 2 values, 'train' or 'test'\n",
    "\n",
    "    Outputs:\n",
    "        A: = g(Z), where Z = WA + b, where Z is the numpy.ndarray (n_out, m) dimensions\n",
    "        g is the activation function\n",
    "        cache: a dictionary containing the cache from the linear propagation, activation, bacthnorm and dropout\n",
    "        to be used for derivative\n",
    "    '''\n",
    "    \n",
    "    Z, lin_cache = linear_forward(A_prev, W, b)\n",
    "    if activation == \"relu\":\n",
    "        A, act_cache = relu(Z)\n",
    "    elif activation == \"linear\":\n",
    "        A, act_cache = linear(Z)\n",
    "    \n",
    "    A, bnorm_cache = batchnorm(A, bnorm_beta, bnorm_gamma)\n",
    "    A, drop_cache = dropout(A, drop_prob, mode)\n",
    "    cache = {}\n",
    "    cache[\"lin_cache\"] = lin_cache\n",
    "    cache[\"act_cache\"] = act_cache\n",
    "    cache[\"bnorm_cache\"] = bnorm_cache\n",
    "    cache[\"drop_cache\"] = drop_cache\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_layer_forward(A0, parameters, mode):\n",
    "    '''\n",
    "    Forward propgation through the layers of the network\n",
    "\n",
    "    Inputs: \n",
    "        A0: numpy.ndarray (n,m) with n features and m samples\n",
    "        parameters: dictionary of network parameters {\"W1\":[..],\"b1\":[..],\"W2\":[..],\"b2\":[..]...}\n",
    "        mode: 'train' or 'test' Dropout acts differently in training and testing mode. Hence, mode is a parameter which\n",
    "                takes in only 2 values, 'train' or 'test' \n",
    "    \n",
    "    Outputs:\n",
    "        AL: numpy.ndarray (c,m)  - outputs of the last fully connected layer before softmax\n",
    "            where c is number of categories and m is number of samples\n",
    "        caches: a list of caches from every layer after forward propagation\n",
    "    '''\n",
    "    \n",
    "    L = parameters['numLayers']\n",
    "    A = A0\n",
    "    caches = []\n",
    "    for l in range(L):\n",
    "        A, cache = layer_forward(A, parameters[\"W\"+str(l+1)], parameters[\"b\"+str(l+1)], \\\n",
    "                                 parameters[\"act\"+str(l+1)], parameters[\"dropout\"+str(l+1)], \\\n",
    "                                 parameters['bnorm_beta'+str(l+1)], parameters['bnorm_gamma'+str(l+1)], mode)\n",
    "        caches.append(cache)\n",
    "    return A, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache, W, b):\n",
    "    '''\n",
    "    Backward prpagation through the linear layer\n",
    "\n",
    "    Inputs:\n",
    "        dZ: numpy.ndarray (n,m) derivative dL/dz \n",
    "        cache: a dictionary containing the inputs A, for the linear layer\n",
    "            where Z = WA + b,    \n",
    "            Z is (n,m); W is (n,p); A is (p,m); b is (n,1)\n",
    "        W: numpy.ndarray (n,p)\n",
    "        b: numpy.ndarray (n,1)\n",
    "\n",
    "    Outputs:\n",
    "        dA_prev: numpy.ndarray (p,m) the derivative to the previous layer\n",
    "        dW: numpy.ndarray (n,p) the gradient of W \n",
    "        db: numpy.ndarray (n,1) the gradient of b\n",
    "    '''\n",
    "    \n",
    "    A = cache[\"A\"]\n",
    "    # your code here\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    dW = np.dot(dZ, np.transpose(A))\n",
    "    db = np.sum(dZ, axis =1, keepdims =True)\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_backward(dA, cache, W, b, activation):\n",
    "    '''\n",
    "    Backward propagation through the activation and linear layer\n",
    "\n",
    "    Inputs:\n",
    "        dA: numpy.ndarray (n,m) the derivative to the previous layer\n",
    "        cache: dictionary containing the linear_cache and the activation_cache\n",
    "        W: numpy.ndarray (n,p)\n",
    "        b: numpy.ndarray (n,1)\n",
    "        activation: activation of the layer, 'relu' or 'linear'\n",
    "    \n",
    "    Outputs:\n",
    "        dA_prev: numpy.ndarray (p,m) the derivative to the previous layer\n",
    "        dW: numpy.ndarray (n,p) the gradient of W \n",
    "        db: numpy.ndarray (n,1) the gradient of b\n",
    "        dbnorm_beta: numpy.ndarray (n,1) derivative of beta for the batchnorm layer\n",
    "        dbnorm_gamma: numpy.ndarray (n,1) derivative of gamma for the batchnorm layer\n",
    "    '''\n",
    "\n",
    "    lin_cache = cache[\"lin_cache\"]\n",
    "    act_cache = cache[\"act_cache\"]\n",
    "    drop_cache = cache[\"drop_cache\"]\n",
    "    bnorm_cache = cache[\"bnorm_cache\"]\n",
    "    \n",
    "    dA = dropout_der(dA, drop_cache)\n",
    "    dA, dbnorm_beta, dbnorm_gamma = batchnorm_der(dA, cache[\"bnorm_cache\"])\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_der(dA, act_cache)\n",
    "    elif activation == \"linear\":\n",
    "        dZ = linear_der(dA, act_cache)\n",
    "        \n",
    "    dA_prev, dW, db = linear_backward(dZ, lin_cache, W, b)\n",
    "    return dA_prev, dW, db, dbnorm_beta, dbnorm_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_layer_backward(dAL, caches, parameters):\n",
    "    '''\n",
    "    Back propgation through the layers of the network (except softmax cross entropy)\n",
    "    softmax_cross_entropy can be handled separately\n",
    "\n",
    "    Inputs: \n",
    "        dAL: numpy.ndarray (n,m) derivatives from the softmax_cross_entropy layer\n",
    "        caches: a dictionary of associated caches of parameters and network inputs\n",
    "        parameters: dictionary of network parameters {\"W1\":[..],\"b1\":[..],\"W2\":[..],\"b2\":[..]...}\n",
    "\n",
    "    Outputs:\n",
    "        gradients: dictionary of gradient of network parameters \n",
    "            {\"dW1\":[..],\"db1\":[..],\"dW2\":[..],\"db2\":[..],...\\\n",
    "            \"dbnorm_beta1\":[..],\"dbnorm_gamma1\":[..],\"dbnorm_beta2\":[..],\"dbnorm_gamma2\":[..],...}\n",
    "    '''\n",
    "\n",
    "    L = len(caches) \n",
    "    gradients = {}\n",
    "    dA = dAL\n",
    "    activation = \"linear\"\n",
    "    for l in reversed(range(L)):\n",
    "        dA, gradients[\"dW\"+str(l+1)], gradients[\"db\"+str(l+1)], \\\n",
    "        gradients[\"dbnorm_beta\"+str(l+1)], gradients[\"dbnorm_gamma\"+str(l+1)] \\\n",
    "                    = layer_backward(dA, caches[l], parameters[\"W\"+str(l+1)],\\\n",
    "                                     parameters[\"b\"+str(l+1)],parameters[\"act\"+str(l+1)])\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_with_momentum_Adam(parameters, gradients, alpha, beta=0.9, beta2=0.99, eps=1e-8):\n",
    "    '''\n",
    "    Updates the network parameters with gradient descent\n",
    "\n",
    "    Inputs:\n",
    "        parameters: dictionary of \n",
    "                    network parameters, {\"W1\":[..],\"b1\":[..],\"W2\":[..],\"b2\":[..],...}\n",
    "                    velocity parameters, {\"VdW1\":[..],\"Vdb1\":[..],\"VdW2\":[..],\"Vdb2\":[..],...}\n",
    "                    Gradient-Squares parameters, {\"GdW1\":[..],\"Gdb1\":[..],\"GdW2\":[..],\"Gdb2\":[..],...}\n",
    "                    batchnorm parameters, {\"bnorm_beta1\":[..],\"bnorm_gamma1\":[..],\"bnorm_beta2\":[..],\"bnorm_gamma2\":[..],...}\n",
    "                    batchnorm velocity parameters, {\"Vbnorm_beta1\":[..],\"Vbnorm_gamma1\":[..],\"Vbnorm_beta2\":[..],\"Vbnorm_gamma2\":[..],...}\n",
    "                    batchnorm Gradient-Square parameters, {\"Gbnorm_beta1\":[..],\"Gbnorm_gamma1\":[..],\"Gbnorm_beta2\":[..],\"Gbnorm_gamma2\":[..],...}\n",
    "                    and other parameters \n",
    "                    :\n",
    "                    :\n",
    "                    Note: It is just one dictionary (parameters) with all these key value pairs, not multiple dictionaries\n",
    "        gradients: dictionary of gradient of network parameters \n",
    "                   {\"dW1\":[..],\"db1\":[..],\"dW2\":[..],\"db2\":[..],...}\n",
    "        alpha: stepsize for the gradient descent\n",
    "        beta: beta parameter for momentum (same as beta1 in Adam)\n",
    "        beta2: beta2 parameter for Adam\n",
    "        eps: epsilon parameter for Adam\n",
    "        \n",
    "    Outputs: \n",
    "        parameters: updated dictionary of \n",
    "                    network parameters, {\"W1\":[..],\"b1\":[..],\"W2\":[..],\"b2\":[..],...}\n",
    "                    velocity parameters, {\"VdW1\":[..],\"Vdb1\":[..],\"VdW2\":[..],\"Vdb2\":[..],...}\n",
    "                    Gradient-Squares parameters, {\"GdW1\":[..],\"Gdb1\":[..],\"GdW2\":[..],\"Gdb2\":[..],...}\n",
    "                    batchnorm parameters, {\"bnorm_beta1\":[..],\"bnorm_gamma1\":[..],\"bnorm_beta2\":[..],\"bnorm_gamma2\":[..],...}\n",
    "                    batchnorm velocity parameters, {\"Vbnorm_beta1\":[..],\"Vbnorm_gamma1\":[..],\"Vbnorm_beta2\":[..],\"Vbnorm_gamma2\":[..],...}\n",
    "                    batchnorm Gradient-Square parameters, {\"Gbnorm_beta1\":[..],\"Gbnorm_gamma1\":[..],\"Gbnorm_beta2\":[..],\"Gbnorm_gamma2\":[..],...}\n",
    "                    and other parameters \n",
    "                    :\n",
    "                    :\n",
    "                    Note: It is just one dictionary (parameters) with all these key value pairs, not multiple dictionaries\n",
    "             \n",
    "    '''\n",
    "    L = parameters['numLayers']\n",
    "    apply_momentum = parameters['apply_momentum']\n",
    "    bnorm_list = parameters['bnorm_list']\n",
    "    \n",
    "    for l in range(L):\n",
    "        if apply_momentum:\n",
    "            # Apply Adam momentum to parameters W's and b's. \n",
    "            # You will need to update the Velocity parameters VdW's and Vdb's\n",
    "            # parameters[\"VdW\" + str(l+1)] = \n",
    "            # parameters[\"Vdb\" + str(l+1)] =\n",
    "            # You will need to update the Gradient-Squares parameters GdW's and Gdb's\n",
    "            # parameters[\"GdW\" + str(l+1)] = \n",
    "            # parameters[\"Gdb\" + str(l+1)] =\n",
    "            # You will need to update the parameters W's and b's\n",
    "            # parameters[\"W\" + str(l+1)] = \n",
    "            # parameters[\"b\" + str(l+1)] = \n",
    "            # your code here\n",
    "            \n",
    "            # Momentum (velosity) beta\n",
    "            parameters[\"VdW\" + str(l+1)] = beta * parameters[\"VdW\" + str(l+1)] + (1-beta)* gradients[\"dW\" + str(l+1)]\n",
    "            parameters[\"Vdb\" + str(l+1)] = beta * parameters[\"Vdb\" + str(l+1)] + (1-beta)* gradients[\"db\" + str(l+1)]\n",
    "            \n",
    "            # RMSProp (Gradient-Squares) beta2\n",
    "            parameters[\"GdW\" + str(l+1)] = beta2 * parameters[\"GdW\" + str(l+1)] + (1-beta2)* (gradients[\"dW\" + str(l+1)])**2\n",
    "            parameters[\"Gdb\" + str(l+1)] = beta2 * parameters[\"Gdb\" + str(l+1)] + (1-beta2)* (gradients[\"db\" + str(l+1)])**2\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Update the parameters W's and b's\n",
    "            w_factor = (alpha * parameters[\"VdW\" + str(l+1)])/np.sqrt(parameters[\"GdW\" + str(l+1)]+eps)\n",
    "            parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - w_factor\n",
    "            \n",
    "            b_factor = (alpha * parameters[\"Vdb\" + str(l+1)])/np.sqrt(parameters[\"Gdb\" + str(l+1)]+eps)\n",
    "            parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - b_factor\n",
    "            \n",
    "        else:\n",
    "            # When no momentum is required apply regular gradient descent\n",
    "            parameters[\"W\"+str(l+1)] -= alpha * gradients[\"dW\"+str(l+1)]\n",
    "            parameters[\"b\"+str(l+1)] -= alpha * gradients[\"db\"+str(l+1)]\n",
    "        \n",
    "        # The Adam momentum for batch norm parameters has been implemented below\n",
    "        if apply_momentum and bnorm_list[l]:\n",
    "            parameters['Vbnorm_beta'+str(l+1)] = beta*parameters['Vbnorm_beta'+str(l+1)] + \\\n",
    "                                                    (1 - beta)*gradients[\"dbnorm_beta\"+str(l+1)]\n",
    "            parameters['Vbnorm_gamma'+str(l+1)] = beta*parameters['Vbnorm_gamma'+str(l+1)] + \\\n",
    "                                                    (1 - beta)*gradients[\"dbnorm_gamma\"+str(l+1)]\n",
    "            parameters['Gbnorm_beta'+str(l+1)] = beta2*parameters['Gbnorm_beta'+str(l+1)] + \\\n",
    "                                                    (1 - beta2)*(gradients[\"dbnorm_beta\"+str(l+1)]**2)\n",
    "            parameters['Gbnorm_gamma'+str(l+1)] = beta2*parameters['Gbnorm_gamma'+str(l+1)] + \\\n",
    "                                                    (1 - beta2)*(gradients[\"dbnorm_gamma\"+str(l+1)]**2)\n",
    "            parameters['bnorm_beta' + str(l+1)] = parameters['bnorm_beta' + str(l+1)] \\\n",
    "                        - alpha*parameters['Vbnorm_beta'+str(l+1)]/np.sqrt(parameters['Gbnorm_beta'+str(l+1)] + eps)\n",
    "            parameters['bnorm_gamma' + str(l+1)] = parameters['bnorm_gamma' + str(l+1)] \\\n",
    "                        - alpha*parameters['Vbnorm_gamma'+str(l+1)]/np.sqrt(parameters['Gbnorm_gamma'+str(l+1)] + eps)\n",
    "        elif bnorm_list[l]:\n",
    "            parameters['bnorm_beta' + str(l+1)] -= alpha * gradients[\"dbnorm_beta\"+str(l+1)]\n",
    "            parameters['bnorm_gamma' + str(l+1)] -= alpha * gradients[\"dbnorm_beta\"+str(l+1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_layer_network(X, Y, net_dims, act_list, drop_prob_list, bnorm_list, num_epochs=3, \n",
    "                        batch_size=64, learning_rate=0.2, decay_rate=0.01, apply_momentum=True, log=True, log_step=200):\n",
    "    \n",
    "    '''\n",
    "    Creates the multilayer network and trains the network\n",
    "\n",
    "    Inputs:\n",
    "        X: numpy.ndarray (n,m) of training data\n",
    "        Y: numpy.ndarray (1,m) of training data labels\n",
    "        net_dims: tuple of layer dimensions\n",
    "        act_list: list of strings indicating the activations for each layer\n",
    "        drop_prob_list: list of dropout probabilities for each layer \n",
    "        bnorm_list: binary list indicating presence or absence of batchnorm for each layer\n",
    "        num_epochs: num of epochs to train\n",
    "        batch_size: batch size for training\n",
    "        learning_rate: learning rate for gradient descent\n",
    "        decay_rate: rate of learning rate decay\n",
    "        apply_momentum: boolean whether to apply momentum or not\n",
    "        log: boolean whether to print training progression \n",
    "        log_step: prints training progress every log_step iterations\n",
    "    \n",
    "    Outputs:\n",
    "        costs: list of costs (or loss) over training\n",
    "        parameters: dictionary of \n",
    "                    network parameters, {\"W1\":[..],\"b1\":[..],\"W2\":[..],\"b2\":[..],...}\n",
    "                    velocity parameters, {\"VdW1\":[..],\"Vdb1\":[..],\"VdW2\":[..],\"Vdb2\":[..],...}\n",
    "                    Gradient-Squares parameters, {\"GdW1\":[..],\"Gdb1\":[..],\"GdW2\":[..],\"Gdb2\":[..],...}\n",
    "                    batchnorm parameters, {\"bnorm_beta1\":[..],\"bnorm_gamma1\":[..],\"bnorm_beta2\":[..],\"bnorm_gamma2\":[..],...}\n",
    "                    batchnorm velocity parameters, {\"Vbnorm_beta1\":[..],\"Vbnorm_gamma1\":[..],\"Vbnorm_beta2\":[..],\"Vbnorm_gamma2\":[..],...}\n",
    "                    batchnorm Gradient-Square parameters, {\"Gbnorm_beta1\":[..],\"Gbnorm_gamma1\":[..],\"Gbnorm_beta2\":[..],\"Gbnorm_gamma2\":[..],...}\n",
    "                    Note: It is just one dictionary (parameters) with all these key value pairs, not multiple dictionaries\n",
    "    '''\n",
    "    mode = 'train'\n",
    "    n, m = X.shape\n",
    "    parameters = initialize_network(net_dims, act_list, drop_prob_list)\n",
    "    parameters = initialize_velocity(parameters, apply_momentum)\n",
    "    parameters = initialize_bnorm_params(parameters, bnorm_list, apply_momentum)\n",
    "    costs = []\n",
    "    itr = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        # estimate stepsize alpha using decay_rate on learning rate using epoch number\n",
    "        alpha = learning_rate*(1/(1+decay_rate*epoch))\n",
    "        if log:\n",
    "            print('------- Epoch {} -------'.format(epoch+1))\n",
    "        for ii in range((m - 1) // batch_size + 1):\n",
    "            Xb = X[:, ii*batch_size : (ii+1)*batch_size]\n",
    "            Yb = Y[:, ii*batch_size : (ii+1)*batch_size]\n",
    "            A0 = Xb\n",
    "        \n",
    "            ## Forward Propagation\n",
    "            # Step 1: Input 'A0', 'parameters' and 'mode' into the network \n",
    "            #         using multi_layer_forward() and calculate output of last layer 'A' (before softmax) \n",
    "            #         and obtain cached activations as 'caches'\n",
    "            # Step 2: Input 'A' and groundtruth labels 'Yb' to softmax_cross_entropy_loss(.) and estimate\n",
    "            #         activations 'AL', 'softmax_cache' and 'cost'\n",
    "\n",
    "            ## Back Propagation\n",
    "            # Step 3: Estimate gradient 'dAL' with softmax_cross_entropy_loss_der(.) using groundtruth \n",
    "            #         labels 'Yb' and 'softmax_cache' \n",
    "            # Step 4: Estimate 'gradients' with multi_layer_backward(.) using 'dAL', 'caches' and 'parameters' \n",
    "            # Step 5: Estimate updated 'parameters' with update_parameters_with_momentum_Adam(.) \n",
    "            #         using 'parameters', 'gradients' and 'alpha'\n",
    "            #         Note: Use the same variable 'parameters' as input and output to the update_parameters(.) function\n",
    "        \n",
    "            # your code here\n",
    "            ## Forward Propagation\n",
    "            A,caches = multi_layer_forward(A0, parameters, mode)\n",
    "            AL,softmax_cache,cost = softmax_cross_entropy_loss(A,Yb)\n",
    "            \n",
    "            ## Back Propagation\n",
    "            dAL = softmax_cross_entropy_loss_der(Yb, softmax_cache)\n",
    "            gradients = multi_layer_backward(dAL, caches, parameters)\n",
    "            parameters = update_parameters_with_momentum_Adam(parameters, gradients, alpha)\n",
    "            \n",
    "\n",
    "            if itr % log_step == 0:\n",
    "                costs.append(cost)\n",
    "                if log:\n",
    "                    print(\"Cost at iteration %i is: %.05f, learning rate: %.05f\" %(itr, cost, alpha))\n",
    "            itr+=1\n",
    "    \n",
    "    return costs, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X, parameters, mode='test'):\n",
    "    '''\n",
    "    Network prediction for inputs X\n",
    "\n",
    "    Inputs: \n",
    "        X: numpy.ndarray (n,m) with n features and m samples\n",
    "        parameters: dictionary of network parameters \n",
    "            {\"W1\":[..],\"b1\":[..],\"W2\":[..],\"b2\":[..],...}\n",
    "        drop_prob_list: list of dropout probabilities for each layer \n",
    "        mode: 'train' or 'test' Dropout acts differently in training and testing mode.\n",
    "        \n",
    "    Outputs:\n",
    "        YPred: numpy.ndarray (1,m) of predictions\n",
    "    '''\n",
    "    # Using multi_layer_forward(.) Forward propagate input 'X' with 'parameters' and mode to \n",
    "    #        obtain the final activation 'A'\n",
    "    # Using 'softmax_cross_entropy loss(.)', obtain softmax activation 'AL' with input 'A' from step 1\n",
    "    # Estimate 'YPred' as the 'argmax' of softmax activation from step-2. These are the label predictions \n",
    "    # Note: the shape of 'YPred' should be (1,m), where m is the number of samples\n",
    "    \n",
    "    # your code here\n",
    "    A,_ = multi_layer_forward(X, parameters, mode)\n",
    "    AL,_,_ = softmax_cross_entropy_loss(A)\n",
    "    YPred = np.argmax(AL, axis =0).reshape(1,-1)\n",
    "    \n",
    "    \n",
    "    return YPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network dimensions are:[784, 100, 100, 64, 10]\n",
      "Dropout= [[0, 0, 0, 0]], Batch Size = 128, lr = 0.01, decay rate = 1\n",
      "------- Epoch 1 -------\n",
      "Cost at iteration 0 is: 3.12612, learning rate: 0.01000\n",
      "Cost at iteration 200 is: 0.25735, learning rate: 0.01000\n",
      "Cost at iteration 400 is: 0.27297, learning rate: 0.01000\n",
      "------- Epoch 2 -------\n",
      "Cost at iteration 600 is: 0.14606, learning rate: 0.00500\n",
      "Cost at iteration 800 is: 0.21278, learning rate: 0.00500\n",
      "Accuracy for training set is 96.507 %\n",
      "Accuracy for testing set is 95.900 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You should be able to get a train accuracy of >90% and a test accuracy >85% \n",
    "# The settings below gave >95% train accuracy and >90% test accuracy \n",
    "\n",
    "# Feel free to adjust the values and explore how the network behaves\n",
    "net_dims = [784, 100, 100, 64, 10] # This network has 4 layers\n",
    "#784 is for image dimensions\n",
    "#10 is for number of categories \n",
    "#100 and 64 are arbitrary\n",
    "\n",
    "# list of dropout probabilities for each layer\n",
    "# The length of the list is equal to the number of layers\n",
    "# Note: Has to be same length as net_dims. 0 indicates no dropout\n",
    "drop_prob_list = [0, 0, 0, 0]\n",
    "\n",
    "# binary list indicating if batchnorm should be implemented for a layer\n",
    "# The length of the list is equal to the number of layers\n",
    "# 1 indicates bathnorm and 0 indicates no batchnorm\n",
    "# If your implementation of batchnorm is incorrect, then set bnorm_list = [0,0,0,0]\n",
    "bnorm_list = [1,1,1,1]\n",
    "assert(len(bnorm_list) == len(net_dims)-1)\n",
    "\n",
    "# list of strings indicating the activation for a layer\n",
    "# The length of the list is equal to the number of layers\n",
    "# The last layer is usually a linear before the softmax\n",
    "act_list = ['relu', 'relu', 'relu', 'linear']\n",
    "assert(len(act_list) == len(net_dims)-1)\n",
    "    \n",
    "# initialize learning rate, decay_rate and num_iterations \n",
    "num_epochs = 2  #3\n",
    "batch_size = 128 #64\n",
    "learning_rate = 1e-2\n",
    "decay_rate = 1\n",
    "apply_momentum = True\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "print(\"Network dimensions are:\" + str(net_dims))\n",
    "print('Dropout= [{}], Batch Size = {}, lr = {}, decay rate = {}'\\\n",
    "      .format(drop_prob_list,batch_size,learning_rate,decay_rate)) \n",
    "\n",
    "# getting the subset dataset from MNIST\n",
    "trX, trY, tsX, tsY = get_mnist()\n",
    "# We need to reshape the data everytime to match the format (d,m), where d is dimensions (784) and m is number of samples\n",
    "trX = trX.reshape(-1, 28*28).T\n",
    "trY = trY.reshape(1, -1)\n",
    "tsX = tsX.reshape(-1, 28*28).T\n",
    "tsY = tsY.reshape(1, -1)\n",
    "\n",
    "costs, parameters = multi_layer_network(trX, trY, net_dims, act_list, drop_prob_list, bnorm_list, \\\n",
    "                                        num_epochs=num_epochs, batch_size=batch_size, learning_rate=learning_rate, \\\n",
    "                                        decay_rate=decay_rate, apply_momentum=apply_momentum, log=True)\n",
    "\n",
    "# compute the accuracy for training set and testing set\n",
    "train_Pred = classify(trX, parameters)\n",
    "\n",
    "test_Pred = classify(tsX, parameters)\n",
    "\n",
    "# Estimate the training accuracy 'trAcc' comparing train_Pred and trY \n",
    "# Estimate the testing accuracy 'teAcc' comparing test_Pred and tsY\n",
    "# your code here\n",
    "trAcc = (trY == train_Pred).mean()*100\n",
    "teAcc = (tsY == test_Pred).mean() *100\n",
    "\n",
    "print(\"Accuracy for training set is {0:0.3f} %\".format(trAcc))\n",
    "print(\"Accuracy for testing set is {0:0.3f} %\".format(teAcc))\n",
    "\n",
    "plt.plot(range(len(costs)),costs)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following set up gives an accuracy of > 96% for both test and train. \n",
    "# Feel free to change the settings to get the best accuracy \n",
    "np.random.seed(1)\n",
    "\n",
    "net_dims = [784, 100, 100, 10] \n",
    "drop_prob_list = [0, 0, 0]\n",
    "act_list = ['relu', 'relu', 'linear']\n",
    "    \n",
    "# initialize learning rate, decay_rate and num_iterations \n",
    "num_epochs = 2 #3\n",
    "batch_size = 128  #64\n",
    "learning_rate = 1e-3\n",
    "decay_rate = 0.1\n",
    "apply_momentum = True\n",
    "\n",
    "# If your implementation of batchnorm is incorrect, \n",
    "# then set bnorm_list = [0,0,0] below to run the following testcase without batchnorm. \n",
    "# The test case is still expected to pass without batchnorm when your accuracy is above 95%\n",
    "bnorm_list = [1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the subset dataset from MNIST\n",
    "trX, trY, tsX, tsY = get_mnist()\n",
    "# We need to reshape the data everytime to match the format (d,m), where d is dimensions (784) and m is number of samples\n",
    "trX = trX.reshape(-1, 28*28).T\n",
    "trY = trY.reshape(1, -1)\n",
    "tsX = tsX.reshape(-1, 28*28).T\n",
    "tsY = tsY.reshape(1, -1)\n",
    "\n",
    "costs, parameters = multi_layer_network(trX, trY, net_dims, act_list, drop_prob_list, bnorm_list, \\\n",
    "                                        num_epochs=num_epochs, batch_size=batch_size, learning_rate=learning_rate, \\\n",
    "                                        decay_rate=decay_rate, apply_momentum=apply_momentum, log=False)\n",
    "\n",
    "# compute the accuracy for training set and testing set\n",
    "train_Pred = classify(trX, parameters)\n",
    "test_Pred = classify(tsX, parameters)\n",
    "\n",
    "# Contains hidden tests \n",
    "# Should get atleast 95% train and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
